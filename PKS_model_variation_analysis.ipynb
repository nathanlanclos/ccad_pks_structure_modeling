{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AlphaFold Model Variation Analysis\n",
        "\n",
        "This notebook analyzes **structural variation between different AlphaFold prediction models** (model_0, model_1, model_2, etc.) for PKS proteins.\n",
        "\n",
        "## Purpose\n",
        "- Quantify how much structural predictions vary between models\n",
        "- Identify which structural features are most/least variable\n",
        "- Understand implications for using single vs. ensemble predictions\n",
        "- Guide decisions about which model(s) to use for downstream analysis\n",
        "\n",
        "## Key Questions\n",
        "1. How consistent are structural measurements across models?\n",
        "2. Do some domains show more variation than others?\n",
        "3. Are certain properties (SASA, Rg, volume) more robust than others?\n",
        "4. Should we average across models or use a single representative?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(\"Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Load Data and Extract Model Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load both domain and module macroproperties\n",
        "domain_mp = pd.read_csv('domain_macroproperties.csv', index_col=0)\n",
        "module_mp = pd.read_csv('MP_PKS.csv')\n",
        "\n",
        "print(f\"Domain macroproperties: {domain_mp.shape}\")\n",
        "print(f\"Module macroproperties: {module_mp.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract model number and base structure from filenames\n",
        "def extract_model_info(filename):\n",
        "    \"\"\"Extract model number and base structure identifier from filename\"\"\"\n",
        "    # Pattern: domain_MP_fold_BGC0000001p1_abyB1_SingleModule_M0_Core_model_0_ACP_0860-0930.npz\n",
        "    # or: MP_fold_bgc0000001p1_abyb1_singlemodule_m0_core_model_0.npz\n",
        "    \n",
        "    # Extract model number\n",
        "    model_match = re.search(r'model_(\\d+)', filename.lower())\n",
        "    model_num = int(model_match.group(1)) if model_match else None\n",
        "    \n",
        "    # Extract base structure (everything before model_X)\n",
        "    base_match = re.search(r'(.+)_model_\\d+', filename.lower())\n",
        "    base_structure = base_match.group(1) if base_match else None\n",
        "    \n",
        "    # Extract domain type (for domain data)\n",
        "    domain_match = re.search(r'_([A-Za-z]+)_\\d+-\\d+\\.npz$', filename)\n",
        "    domain_type = domain_match.group(1) if domain_match else None\n",
        "    \n",
        "    # Extract BGC and module info\n",
        "    bgc_match = re.search(r'bgc(\\d+)p(\\d+)', filename.lower())\n",
        "    module_match = re.search(r'_(m\\d+)_', filename.lower())\n",
        "    \n",
        "    return {\n",
        "        'model_num': model_num,\n",
        "        'base_structure': base_structure,\n",
        "        'domain_type': domain_type,\n",
        "        'bgc': bgc_match.group(0) if bgc_match else None,\n",
        "        'module': module_match.group(1).upper() if module_match else None\n",
        "    }\n",
        "\n",
        "# Apply to domain data\n",
        "domain_info = domain_mp['filename'].apply(extract_model_info).apply(pd.Series)\n",
        "domain_mp = pd.concat([domain_mp, domain_info], axis=1)\n",
        "\n",
        "# Apply to module data\n",
        "module_info = module_mp['filename'].apply(extract_model_info).apply(pd.Series)\n",
        "module_mp = pd.concat([module_mp, module_info], axis=1)\n",
        "\n",
        "print(\"Model distribution in domain data:\")\n",
        "print(domain_mp['model_num'].value_counts().sort_index())\n",
        "print(f\"\\nModel distribution in module data:\")\n",
        "print(module_mp['model_num'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Module-Level Model Variation Analysis\n",
        "\n",
        "Analyze how structural properties vary across AlphaFold models for the same module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate variation statistics for each unique module across its models\n",
        "# Group by base_structure (which identifies the same protein/module)\n",
        "\n",
        "numeric_cols = ['n_ca_atoms', 'n_heavy_atoms', 'radius_of_gyration_ca', 'sasa', 'ses_area', 'vdw_volume']\n",
        "\n",
        "# Calculate per-structure variation (across models)\n",
        "module_variation = module_mp.groupby('base_structure')[numeric_cols].agg(['mean', 'std', 'min', 'max', 'count'])\n",
        "\n",
        "# Calculate coefficient of variation (CV = std/mean * 100)\n",
        "module_cv = pd.DataFrame()\n",
        "for col in numeric_cols:\n",
        "    module_cv[col] = (module_variation[(col, 'std')] / module_variation[(col, 'mean')] * 100)\n",
        "\n",
        "print(\"Coefficient of Variation (%) across models per structure:\")\n",
        "print(module_cv.describe().round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize coefficient of variation distributions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    ax = axes[i]\n",
        "    data = module_cv[col].dropna()\n",
        "    ax.hist(data, bins=50, edgecolor='black', alpha=0.7, color=plt.cm.viridis(i/len(numeric_cols)))\n",
        "    ax.axvline(data.median(), color='red', linestyle='--', linewidth=2, label=f'Median: {data.median():.2f}%')\n",
        "    ax.axvline(data.mean(), color='orange', linestyle=':', linewidth=2, label=f'Mean: {data.mean():.2f}%')\n",
        "    ax.set_xlabel('Coefficient of Variation (%)')\n",
        "    ax.set_ylabel('Count (structures)')\n",
        "    ax.set_title(f'{col}\\nModel-to-Model Variation')\n",
        "    ax.legend(fontsize=9)\n",
        "\n",
        "plt.suptitle('How Much Do AlphaFold Models Vary? (Module Level)', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY: Average Coefficient of Variation Across Models\")\n",
        "print(\"=\"*60)\n",
        "for col in numeric_cols:\n",
        "    cv = module_cv[col].dropna()\n",
        "    print(f\"{col:25s}: {cv.mean():.3f}% (median: {cv.median():.3f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare specific models (model_0 vs others)\n",
        "# Create wide format for paired comparisons\n",
        "\n",
        "model_comparison = module_mp.pivot_table(\n",
        "    index='base_structure',\n",
        "    columns='model_num',\n",
        "    values=numeric_cols,\n",
        "    aggfunc='first'\n",
        ")\n",
        "\n",
        "# Compare model 0 vs model 1, 2, 3, 4\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    ax = axes[i]\n",
        "    for model_num in [1, 2, 3, 4]:\n",
        "        if (col, 0) in model_comparison.columns and (col, model_num) in model_comparison.columns:\n",
        "            x = model_comparison[(col, 0)]\n",
        "            y = model_comparison[(col, model_num)]\n",
        "            mask = ~(x.isna() | y.isna())\n",
        "            if mask.sum() > 10:\n",
        "                corr = x[mask].corr(y[mask])\n",
        "                ax.scatter(x[mask], y[mask], alpha=0.3, s=10, label=f'Model {model_num} (r={corr:.3f})')\n",
        "    \n",
        "    ax.plot([ax.get_xlim()[0], ax.get_xlim()[1]], \n",
        "            [ax.get_xlim()[0], ax.get_xlim()[1]], 'r--', linewidth=2, label='Perfect agreement')\n",
        "    ax.set_xlabel(f'{col} (Model 0)')\n",
        "    ax.set_ylabel(f'{col} (Other models)')\n",
        "    ax.set_title(f'{col}')\n",
        "    ax.legend(fontsize=8, loc='lower right')\n",
        "\n",
        "plt.suptitle('Model 0 vs Other Models: Pairwise Comparisons', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Domain-Level Model Variation Analysis\n",
        "\n",
        "Analyze how individual domain properties vary across models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create unique identifier for each domain instance across models\n",
        "domain_mp['domain_instance'] = domain_mp['base_structure'] + '_' + domain_mp['domain_type'].astype(str)\n",
        "\n",
        "# Calculate variation per domain instance\n",
        "domain_variation = domain_mp.groupby('domain_instance')[numeric_cols].agg(['mean', 'std', 'count'])\n",
        "\n",
        "# Calculate CV for domains\n",
        "domain_cv = pd.DataFrame()\n",
        "for col in numeric_cols:\n",
        "    domain_cv[col] = (domain_variation[(col, 'std')] / domain_variation[(col, 'mean')] * 100)\n",
        "\n",
        "# Add domain type back\n",
        "domain_cv['domain_type'] = domain_cv.index.str.extract(r'_([A-Za-z]+)$')[0].values\n",
        "\n",
        "print(\"Domain-level CV statistics:\")\n",
        "print(domain_cv[numeric_cols].describe().round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare CV by domain type - which domains are most variable?\n",
        "def is_linker(domain_type):\n",
        "    if pd.isna(domain_type) or len(str(domain_type)) <= 2:\n",
        "        return False\n",
        "    return str(domain_type).endswith('L')\n",
        "\n",
        "domain_cv['is_linker'] = domain_cv['domain_type'].apply(is_linker)\n",
        "\n",
        "# Calculate mean CV by domain type for key property (radius of gyration)\n",
        "cv_by_domain = domain_cv.groupby('domain_type')['radius_of_gyration_ca'].agg(['mean', 'std', 'count'])\n",
        "cv_by_domain = cv_by_domain[cv_by_domain['count'] >= 10].sort_values('mean', ascending=False)\n",
        "\n",
        "print(\"Model-to-Model Variation by Domain Type (Radius of Gyration):\")\n",
        "print(cv_by_domain.round(3).head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize domain variation by type\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. CV by domain type - Radius of gyration\n",
        "ax = axes[0, 0]\n",
        "colors = ['#e74c3c' if is_linker(d) else '#3498db' for d in cv_by_domain.index]\n",
        "ax.barh(cv_by_domain.index, cv_by_domain['mean'], xerr=cv_by_domain['std'], \n",
        "        color=colors, alpha=0.7, capsize=3)\n",
        "ax.set_xlabel('Mean CV (%) for Radius of Gyration')\n",
        "ax.set_ylabel('Domain Type')\n",
        "ax.set_title('Model Variation by Domain Type\\n(Radius of Gyration)')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# 2. CV by domain type - SASA\n",
        "cv_sasa = domain_cv.groupby('domain_type')['sasa'].agg(['mean', 'std', 'count'])\n",
        "cv_sasa = cv_sasa[cv_sasa['count'] >= 10].sort_values('mean', ascending=False)\n",
        "ax = axes[0, 1]\n",
        "colors = ['#e74c3c' if is_linker(d) else '#3498db' for d in cv_sasa.index]\n",
        "ax.barh(cv_sasa.index, cv_sasa['mean'], xerr=cv_sasa['std'], \n",
        "        color=colors, alpha=0.7, capsize=3)\n",
        "ax.set_xlabel('Mean CV (%) for SASA')\n",
        "ax.set_ylabel('Domain Type')\n",
        "ax.set_title('Model Variation by Domain Type\\n(SASA)')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# 3. Catalytic vs Linker comparison\n",
        "ax = axes[1, 0]\n",
        "catalytic_cv = domain_cv[~domain_cv['is_linker']]['radius_of_gyration_ca'].dropna()\n",
        "linker_cv = domain_cv[domain_cv['is_linker']]['radius_of_gyration_ca'].dropna()\n",
        "\n",
        "ax.hist(catalytic_cv, bins=30, alpha=0.7, label=f'Catalytic (n={len(catalytic_cv)}, μ={catalytic_cv.mean():.2f}%)', \n",
        "        color='#3498db', density=True)\n",
        "ax.hist(linker_cv, bins=30, alpha=0.7, label=f'Linker (n={len(linker_cv)}, μ={linker_cv.mean():.2f}%)', \n",
        "        color='#e74c3c', density=True)\n",
        "ax.set_xlabel('CV (%) for Radius of Gyration')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Catalytic vs Linker Domain Variation')\n",
        "ax.legend()\n",
        "\n",
        "# 4. CV across all properties comparison\n",
        "ax = axes[1, 1]\n",
        "prop_means = [domain_cv[col].mean() for col in numeric_cols]\n",
        "prop_stds = [domain_cv[col].std() for col in numeric_cols]\n",
        "ax.barh(numeric_cols, prop_means, xerr=prop_stds, color=plt.cm.plasma(np.linspace(0.2, 0.8, len(numeric_cols))), capsize=3)\n",
        "ax.set_xlabel('Mean CV (%)')\n",
        "ax.set_ylabel('Property')\n",
        "ax.set_title('Which Properties Show Most Model Variation?')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Statistical Tests for Model Differences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANOVA test - do models differ significantly?\n",
        "from scipy.stats import f_oneway, kruskal\n",
        "\n",
        "print(\"Statistical Tests: Are models significantly different?\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# For each property, test if models differ\n",
        "for col in numeric_cols:\n",
        "    groups = [module_mp[module_mp['model_num'] == m][col].dropna() for m in range(5)]\n",
        "    groups = [g for g in groups if len(g) > 10]\n",
        "    \n",
        "    if len(groups) >= 2:\n",
        "        # Kruskal-Wallis (non-parametric)\n",
        "        stat, p = kruskal(*groups)\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"  Kruskal-Wallis H={stat:.2f}, p={p:.2e}\")\n",
        "        if p < 0.05:\n",
        "            print(f\"  → Models differ significantly (p < 0.05)\")\n",
        "        else:\n",
        "            print(f\"  → No significant difference between models\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ICC (Intraclass Correlation Coefficient) for model agreement\n",
        "# Higher ICC = better agreement between models\n",
        "\n",
        "def calculate_icc(data, group_col, value_col):\n",
        "    \"\"\"Calculate ICC(2,1) for agreement between raters/models\"\"\"\n",
        "    groups = data.groupby(group_col)[value_col].apply(list)\n",
        "    groups = groups[groups.apply(len) >= 2]\n",
        "    \n",
        "    if len(groups) < 10:\n",
        "        return np.nan\n",
        "    \n",
        "    # Calculate between-group and within-group variance\n",
        "    all_values = []\n",
        "    group_means = []\n",
        "    for g in groups:\n",
        "        all_values.extend(g)\n",
        "        group_means.append(np.mean(g))\n",
        "    \n",
        "    grand_mean = np.mean(all_values)\n",
        "    n_groups = len(groups)\n",
        "    k = np.mean([len(g) for g in groups])\n",
        "    \n",
        "    # Between-group sum of squares\n",
        "    ss_between = sum(len(g) * (np.mean(g) - grand_mean)**2 for g in groups)\n",
        "    # Within-group sum of squares\n",
        "    ss_within = sum(sum((x - np.mean(g))**2 for x in g) for g in groups)\n",
        "    \n",
        "    ms_between = ss_between / (n_groups - 1) if n_groups > 1 else 0\n",
        "    ms_within = ss_within / (n_groups * (k - 1)) if k > 1 else 0\n",
        "    \n",
        "    # ICC(2,1)\n",
        "    icc = (ms_between - ms_within) / (ms_between + (k - 1) * ms_within) if (ms_between + (k - 1) * ms_within) > 0 else 0\n",
        "    return max(0, icc)  # ICC can't be negative in practice\n",
        "\n",
        "print(\"\\nIntraclass Correlation Coefficients (Model Agreement)\")\n",
        "print(\"=\"*60)\n",
        "print(\"Higher ICC = More agreement between models (0-1 scale)\")\n",
        "print()\n",
        "\n",
        "icc_results = {}\n",
        "for col in numeric_cols:\n",
        "    icc = calculate_icc(module_mp.dropna(subset=[col]), 'base_structure', col)\n",
        "    icc_results[col] = icc\n",
        "    print(f\"{col:30s}: ICC = {icc:.4f}\")\n",
        "\n",
        "# Visualize ICC\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "colors = plt.cm.RdYlGn([v for v in icc_results.values()])\n",
        "bars = ax.barh(list(icc_results.keys()), list(icc_results.values()), color=colors)\n",
        "ax.axvline(0.75, color='green', linestyle='--', linewidth=2, label='Good agreement (0.75)')\n",
        "ax.axvline(0.5, color='orange', linestyle='--', linewidth=2, label='Moderate agreement (0.5)')\n",
        "ax.set_xlabel('ICC (Intraclass Correlation)')\n",
        "ax.set_ylabel('Property')\n",
        "ax.set_title('Model Agreement by Property\\n(Higher = More Consistent Predictions)')\n",
        "ax.set_xlim(0, 1)\n",
        "ax.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Recommendations: Single Model vs Ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary and recommendations\n",
        "print(\"=\"*70)\n",
        "print(\"SUMMARY: AlphaFold Model Variation Analysis\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. COEFFICIENT OF VARIATION (CV) SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "for col in numeric_cols:\n",
        "    cv_mean = module_cv[col].mean()\n",
        "    cv_median = module_cv[col].median()\n",
        "    print(f\"   {col:25s}: Mean CV = {cv_mean:.2f}%, Median CV = {cv_median:.2f}%\")\n",
        "\n",
        "print(\"\\n2. MODEL AGREEMENT (ICC) SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "for col, icc in icc_results.items():\n",
        "    agreement = \"Excellent\" if icc > 0.9 else \"Good\" if icc > 0.75 else \"Moderate\" if icc > 0.5 else \"Poor\"\n",
        "    print(f\"   {col:25s}: ICC = {icc:.3f} ({agreement})\")\n",
        "\n",
        "print(\"\\n3. RECOMMENDATIONS:\")\n",
        "print(\"-\" * 50)\n",
        "avg_cv = np.mean([module_cv[col].mean() for col in numeric_cols])\n",
        "avg_icc = np.mean(list(icc_results.values()))\n",
        "\n",
        "if avg_cv < 2.0 and avg_icc > 0.9:\n",
        "    print(\"   ✓ Models show EXCELLENT agreement\")\n",
        "    print(\"   → Using any single model is likely sufficient\")\n",
        "    print(\"   → Model 0 is typically recommended (highest confidence)\")\n",
        "elif avg_cv < 5.0 and avg_icc > 0.75:\n",
        "    print(\"   ✓ Models show GOOD agreement\")\n",
        "    print(\"   → Single model is acceptable for most analyses\")\n",
        "    print(\"   → Consider averaging for publication-quality results\")\n",
        "else:\n",
        "    print(\"   ⚠ Models show MODERATE variation\")\n",
        "    print(\"   → Recommend using ensemble average\")\n",
        "    print(\"   → Report standard deviation across models as uncertainty\")\n",
        "\n",
        "print(f\"\\n   Overall Average CV: {avg_cv:.2f}%\")\n",
        "print(f\"   Overall Average ICC: {avg_icc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ensemble-averaged dataset (for reference)\n",
        "print(\"\\nCreating ensemble-averaged module data...\")\n",
        "\n",
        "module_ensemble = module_mp.groupby('base_structure').agg({\n",
        "    **{col: ['mean', 'std'] for col in numeric_cols},\n",
        "    'module': 'first',\n",
        "    'bgc': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "module_ensemble.columns = ['_'.join(col).strip('_') if isinstance(col, tuple) else col \n",
        "                           for col in module_ensemble.columns]\n",
        "\n",
        "print(f\"Ensemble dataset shape: {module_ensemble.shape}\")\n",
        "print(\"\\nExample ensemble data:\")\n",
        "display(module_ensemble.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AlphaFold Model Variation Analysis\n",
        "\n",
        "This notebook analyzes the **structural variation between different AlphaFold model predictions** (model_0, model_1, model_2, etc.) for PKS modules.\n",
        "\n",
        "## Key Questions:\n",
        "1. How consistent are structural predictions across different models?\n",
        "2. Which structural properties show the most/least variation?\n",
        "3. Which domains or modules show highest prediction uncertainty?\n",
        "4. Should we use a single model, average, or ensemble for downstream analysis?\n",
        "\n",
        "## Data Sources:\n",
        "- `domain_macroproperties.csv` - Individual domain structures\n",
        "- `MP_PKS.csv` - Full module structures\n",
        "- `IDO_out.csv` - Inter-domain spatial relationships\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(\"Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Load and Parse Data\n",
        "\n",
        "Extract model numbers from filenames to enable comparison across predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "domain_mp = pd.read_csv('domain_macroproperties.csv', index_col=0)\n",
        "module_mp = pd.read_csv('MP_PKS.csv')\n",
        "ido_df = pd.read_csv('IDO_out.csv', low_memory=False)\n",
        "\n",
        "print(f\"Domain macroproperties: {domain_mp.shape}\")\n",
        "print(f\"Module macroproperties: {module_mp.shape}\")\n",
        "print(f\"Inter-domain organization: {ido_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract model number and structure identifier from filenames\n",
        "def parse_filename(filename):\n",
        "    \"\"\"Extract model number and base structure ID from filename\"\"\"\n",
        "    # Pattern: ..._model_X.npz or ..._model_X_...\n",
        "    model_match = re.search(r'model_(\\d+)', filename.lower())\n",
        "    model_num = int(model_match.group(1)) if model_match else None\n",
        "    \n",
        "    # Get base structure ID (everything before model_X)\n",
        "    if model_match:\n",
        "        base_id = filename[:model_match.start()].rstrip('_')\n",
        "    else:\n",
        "        base_id = filename.replace('.npz', '')\n",
        "    \n",
        "    return {'model_num': model_num, 'base_id': base_id}\n",
        "\n",
        "# Apply to domain data\n",
        "domain_info = domain_mp['filename'].apply(parse_filename).apply(pd.Series)\n",
        "domain_mp = pd.concat([domain_mp, domain_info], axis=1)\n",
        "\n",
        "# Apply to module data\n",
        "module_info = module_mp['filename'].apply(parse_filename).apply(pd.Series)\n",
        "module_mp = pd.concat([module_mp, module_info], axis=1)\n",
        "\n",
        "print(\"Model number distribution (Modules):\")\n",
        "print(module_mp['model_num'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nModel number distribution (Domains):\")\n",
        "print(domain_mp['model_num'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Module-Level Model Variation Analysis\n",
        "\n",
        "Compare structural properties across the 5 AlphaFold models for each module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group modules by base_id and calculate variation statistics\n",
        "numeric_cols = ['n_ca_atoms', 'n_heavy_atoms', 'radius_of_gyration_ca', 'sasa', 'ses_area', 'vdw_volume']\n",
        "\n",
        "# Calculate coefficient of variation (CV) for each structure across its models\n",
        "module_variation = module_mp.groupby('base_id')[numeric_cols].agg(['mean', 'std', 'count'])\n",
        "\n",
        "# Calculate CV = std/mean for each property\n",
        "for col in numeric_cols:\n",
        "    module_variation[(col, 'cv')] = module_variation[(col, 'std')] / module_variation[(col, 'mean')] * 100\n",
        "\n",
        "# Flatten column names\n",
        "module_variation.columns = ['_'.join(col).strip() for col in module_variation.columns.values]\n",
        "\n",
        "# Filter to structures with multiple models\n",
        "multi_model = module_variation[module_variation[f'{numeric_cols[0]}_count'] > 1].copy()\n",
        "\n",
        "print(f\"Structures with multiple models: {len(multi_model)}\")\n",
        "print(f\"\\nCoefficient of Variation (%) across models:\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for CV across all structures\n",
        "cv_cols = [f'{col}_cv' for col in numeric_cols]\n",
        "cv_summary = multi_model[cv_cols].describe()\n",
        "cv_summary.columns = [c.replace('_cv', '') for c in cv_cols]\n",
        "print(\"CV Statistics (%) - Lower = more consistent across models:\")\n",
        "display(cv_summary.round(4))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
